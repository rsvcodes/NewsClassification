{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Multiclass Text Classification DISTILBERT**"
      ],
      "metadata": {
        "id": "3kL9R5f0tthn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Link - https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv"
      ],
      "metadata": {
        "id": "zExRx-vztp8n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJYEVceEfTky"
      },
      "outputs": [],
      "source": [
        "!pip uninstall transformers==4.20.1 -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install transformers==4.22.1 -q"
      ],
      "metadata": {
        "id": "CinHig4Ofd7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "pIGfBbs7fmN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_probability==0.13.0"
      ],
      "metadata": {
        "id": "RHhOLnm3hXYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow==2.10"
      ],
      "metadata": {
        "id": "YbCdZ_U0_PVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer\n",
        "from transformers import TFDistilBertForSequenceClassification\n",
        "from transformers import TextClassificationPipeline\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import json\n",
        "import gc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopw = stopwords.words('english')\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from plotly.offline import iplot\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "bi51WFrrftHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/bbc-text.csv'"
      ],
      "metadata": {
        "id": "JzuKEmNKiCcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(root_path)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "tDeRPvGziJWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "DaKzDTUpse_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Histogram of the count of text**"
      ],
      "metadata": {
        "id": "zlvzG0BRt2tG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['count'] = df['text'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "iw0cXrmjsmQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "aXydGY2Ysob8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize= (8, 8))\n",
        "\n",
        "sns.displot(df['count'])\n",
        "\n",
        "plt.xlim(0, 1000)\n",
        "\n",
        "plt.xlabel('The num of words ', fontsize = 16)\n",
        "plt.title(\"The Number of Words Distribution\", fontsize = 18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XIybZzJTsqzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bar plot for each of the new category**"
      ],
      "metadata": {
        "id": "YJc4pZiet98Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_count = df['category'].value_counts()\n",
        "\n",
        "categories = category_count.index\n",
        "\n",
        "categories"
      ],
      "metadata": {
        "id": "rE-BT7uVsvE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_count"
      ],
      "metadata": {
        "id": "W4gGDOUGsxUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_count.index"
      ],
      "metadata": {
        "id": "ZgfRfpvoszXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize= (12, 5))\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "sns.barplot(x = category_count.index, y = category_count )\n",
        "\n",
        "for a, p in enumerate(ax.patches):\n",
        "    ax.annotate(f'{categories[a]}\\n' + format(p.get_height(), '.0f'), xy = (p.get_x() + p.get_width() / 2.0, p.get_height()), xytext = (0,-25), size = 13, color = 'white' , ha = 'center', va = 'center', textcoords = 'offset points', bbox = dict(boxstyle = 'round', facecolor='none',edgecolor='white', alpha = 0.5) )\n",
        "\n",
        "plt.xlabel('Categories', size = 15)\n",
        "\n",
        "plt.ylabel('The Number of News', size= 15)\n",
        "\n",
        "plt.xticks(size = 12)\n",
        "\n",
        "plt.title(\"The number of News by Categories\" , size = 18)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FrQDSr35s1us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['category'].unique()"
      ],
      "metadata": {
        "id": "EQ3uhbQDs4-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['encoded_text'] = df['category'].astype('category').cat.codes\n",
        "\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "tNIPLQg3s7--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_texts = df['text'].to_list()\n",
        "\n",
        "data_labels = df['encoded_text'].to_list()"
      ],
      "metadata": {
        "id": "eqxDRwqUs-pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Test SPlit**"
      ],
      "metadata": {
        "id": "JTkXYkCSuDiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(data_texts, data_labels, test_size = 0.2, random_state = 0 )\n",
        "\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(train_texts, train_labels, test_size = 0.01, random_state = 0 )"
      ],
      "metadata": {
        "id": "JYC06q6NtDx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Definition**"
      ],
      "metadata": {
        "id": "HO30Xj5PuGyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation = True, padding = True  )\n",
        "\n",
        "val_encodings = tokenizer(val_texts, truncation = True, padding = True )"
      ],
      "metadata": {
        "id": "KjNi8tMltHa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_labels\n",
        "))\n",
        "\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    val_labels\n",
        "))"
      ],
      "metadata": {
        "id": "NIrKvzZBtM0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning with the TFTrainer class**"
      ],
      "metadata": {
        "id": "yzq3LMTLuNuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=5)"
      ],
      "metadata": {
        "id": "ip_zIqDYtP9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\n",
        "\n",
        "\n",
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=7,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=1e-5,\n",
        "    logging_dir='./logs',\n",
        "    eval_steps=100\n",
        ")\n",
        "\n",
        "with training_args.strategy.scope():\n",
        "    trainer_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 5 )\n",
        "\n",
        "\n",
        "trainer = TFTrainer(\n",
        "    model=trainer_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "buCT-kUetT4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "QccZRHqetWkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "qv5hWhVXtZRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving & Loading the model**"
      ],
      "metadata": {
        "id": "Fpm7DL0kuRpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory = \"/saved_models\"\n",
        "\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "tokenizer.save_pretrained(save_directory)"
      ],
      "metadata": {
        "id": "VfzRui7HtcbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Pre-Trained Model**"
      ],
      "metadata": {
        "id": "PYF-hP65uV4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_fine_tuned = DistilBertTokenizer.from_pretrained(save_directory)\n",
        "\n",
        "model_fine_tuned = TFDistilBertForSequenceClassification.from_pretrained(save_directory)"
      ],
      "metadata": {
        "id": "HSJfPskcte7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = test_texts[1]\n",
        "\n",
        "test_text"
      ],
      "metadata": {
        "id": "HZMfAyehtg_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_input = tokenizer_fine_tuned.encode(\n",
        "    test_text,\n",
        "    truncation = True,\n",
        "    padding = True,\n",
        "    return_tensors = 'tf'\n",
        ")\n",
        "\n",
        "output = model_fine_tuned(predict_input)[0]\n",
        "\n",
        "prediction_value = tf.argmax(output, axis = 1).numpy()[0]\n",
        "\n",
        "prediction_value"
      ],
      "metadata": {
        "id": "afXWky-ztjfo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}